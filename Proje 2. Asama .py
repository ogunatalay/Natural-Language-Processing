# -*- coding: utf-8 -*-
"""bitirmee.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jB4-DA0fQLCcvgLoj5hqfhCNTB_nwwUi
"""

# Gerekli kütüphaneleri yükleme
!pip install jsonlines
!apt-get update -qq
!apt-get install -y openjdk-11-jdk-headless -qq > /dev/null
!wget -q https://github.com/ahmetaa/zemberek-nlp/releases/download/v0.17.1/zemberek-full.jar -O zemberek-full.jar
!pip install py4j
!pip install jpype1
!pip install zemberek-python


import jsonlines
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import nltk
from nltk.corpus import stopwords
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score
from sklearn.pipeline import make_pipeline
from sklearn.decomposition import TruncatedSVD
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Flatten
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.utils.class_weight import compute_class_weight
from zemberek import TurkishMorphology
from py4j.java_gateway import JavaGateway
import jpype
import jpype.imports
from jpype.types import JString
import jsonlines

from google.colab import drive

# Google Drive'ı bağla
drive.mount('/content/drive')

import pandas as pd
# Dosya yolu (Google Drive'daki tam yol)
file_path = "/content/drive/My Drive/train.jsonlines"

# JSON Lines dosyasını okuma
df = pd.read_json(file_path, lines=True)

# İlk birkaç satırı gösterme
print(df.head())

import pandas as pd
from zemberek import TurkishMorphology
from zemberek.tokenization import TurkishTokenizer
import re

# Zemberek'i başlat
morphology = TurkishMorphology.create_with_defaults()
tokenizer = TurkishTokenizer.DEFAULT


# Stopwords ve link temizliği
stop_words = {'https', 'ol', 'co', 'bir', 'var', 't', 've', 'bu', 'da', 'de',
             'için', 'olarak', 'ama', 'yani', 'çok'}

def remove_stopwords_links_and_hashes(input_text):
    input_text = re.sub(r'http\S+|www\S+', '', input_text)  # Linkleri çıkar
    input_text = re.sub(r'#\S+', '', input_text)           # '#' ile başlayan ifadeleri çıkar
    input_text = re.sub(r'@\S+', '', input_text)           # '@' ile başlayan ifadeleri çıkar
    input_text = ' '.join(word for word in input_text.split()
                         if len(word) > 1 and word not in stop_words)
    return input_text

# Metinleri ön işleme
def preprocess_text(input_text):
    input_text = input_text.lower()  # Küçük harfe çevir
    tokens = tokenizer.tokenize(input_text)  # Tokenize et
    stems = []
    for token in tokens:
        analyses = morphology.analyze(token.normalized)  # Kökleri bul
        if analyses.analysis_results:
            best_analysis = analyses.analysis_results[0]
            stems.append(best_analysis.get_stem())  # En iyi analizi al
    return ' '.join(stems)

# Metinleri temizle ve işleme al
df['Processed_Text'] = df['text'].apply(preprocess_text)
df['Processed_Text'] = df['Processed_Text'].apply(remove_stopwords_links_and_hashes)

# Etiketleri sayısal değerlere dönüştürme
df['Offensive_Label'] = df['label'].map({'not-offensive': 0, 'offensive': 1})

# Sonuçları kontrol et
print(df[['text', 'Processed_Text', 'label', 'Offensive_Label']].head())

for i in range(5):
    print(f"Ham Metin: {df['text'].iloc[i]}")
    print(f"Temizlenmiş Metin: {df['Processed_Text'].iloc[i]}")
    print(f"Orijinal Etiket: {df['label'].iloc[i]}")
    print(f"Sayısal Etiket: {df['Offensive_Label'].iloc[i]}")
    print("-" * 50)

# Temizlenmiş veriyi Google Drive'a kaydet
output_file_path = '/content/drive/My Drive/cleaned_data.csv'  # Kaydetmek istediğiniz tam yol
df.to_csv(output_file_path, index=False)

print(f"Temizlenmiş veri CSV dosyasına kaydedildi: {output_file_path}")

# Hakaret kelimelerini belirgin yapmak için ağırlıklandırma fonksiyonu
def generate_wordcloud_with_weights(text_data, title):
    custom_stopwords = stop_words.union({
        'bir', 'bu', 'de', 've', 'ile', 'ben', 'ama', 'çok', 'hiç', 'şu', 'ne', 'neden', 'gibi', 'daha', 'ya', 'ya da',
        'her', 'hiçbir', 'bunu', 'şey', 'oldu', 'olmaz', 'bu kadar', 'kadar', 'sonra', 'önce', 'şimdi',
        'dönem', 'şu an', 'bunu', 'onlar', 'yok', 'oluyor', 'olan', 'şimdiye', 'belki', 'öyle', 'için', 'ki',
        'ama', 'bile', 'hep', 'kim', 'nasıl', 'işte', 'başka', 'onun', 'sizin', 'bizim', 'bunlar', 'arasında',
        'bununla', 'işte', 'tamam', 'sadece', 'göstermek', 'birçok', 'katkı', 'bunu', 'bile', 'nerede', 'en',
        'değil', 'olmak', 'hepsi', 'neden', 'hangi', 'arada', 'çoğu', 'ama', 'sizin', 'biz', 'onlar', 'ama',
        'çünkü', 'şimdi', 'henüz', 'çok', 'daha', 'gerçekten', 'sadece', 'şu', 'ile', 'gibi', 'bunu', 'yani',
        'hadi', 'burası', 'gösterdi', 'göstermek', 'benim', 'onlar', 'hadi', 'ki', 'bak', 'belirli', 'şu kadar',
        'hiçbir zaman', 'bazen', 'gerek', 'bazı', 'için', 'yerine', 'sonunda', 'arasında', 'gibi', 'daha çok',
        'çünkü', 'neden', 'isterseniz', 'neredeyse', 'zaten', 'genellikle', 'aslında', 'henüz', 'neden', 'bunu',
        'kendisi', 'bu yüzden', 'tek', 'birisi', 'birkaç', 'çokça', 'kendi', 'şeyler', 'sonuçta', 'gerçekten',
        'şimdiye kadar', 'öncelikle', 'yapmak', 'olduğu', 'özellikle', 'sadece', 'işte', 'bütün', 'onlarca', 'birde',
        'herkes', 'herhangi', 'tartışmasız', 'belki', 'ya da', 'kesinlikle', 'hemen', 'şunlar', 'bunlar', 'en son',
        'şu şekilde', 'her zaman', 'gerekli', 'daha önce', 'genellikle', 'zaman zaman', 'en iyi', 'çok fazla',
        'hiçbir şekilde', 'bazı şeyler', 'katılıyorum', 'bu kadar', 'her biri', 'sonuç olarak', 'bu da', 'bazı',
        'olabilirdi', 'işin gerçeği', 'en büyük', 'göstermek için', 'çok fazla', 'hepsi', 'tek bir', 'gerçekten',
        'işin sırrı', 'var', 'kötü', 'bi', 'böyle', 'mi', 'iyi', 'artık', 'bana', 'olsun', 'hala', 'olur', 'olmuş',
        'yok', 'bunun', 'i', 'e', '3', '1', '2', '4', '5', '6', '7', '10', '9', '8', 'a', 'böy', '10', '20', '15', '.', '...', 'mı', 'se', 'ed', ':)'   })

    # Kelimelerin sıklığını hesaplayın
    word_frequencies = {}
    for word in ' '.join(text_data).split():
        if word not in custom_stopwords:
            if word in word_frequencies:
                word_frequencies[word] += 1
            else:
                word_frequencies[word] = 1

    # Hakaret kelimeleri listesi
    hate_words = ["şerefsiz", "aptal", "salak", "kötü", "çirkin", "nefret", "gerizekalı", "haksız", "manyak", "amk", "aq", "iğrenç"]

    # Hakaret kelimeleri için özel ağırlıklandırma
    for word in hate_words:
        if word in word_frequencies:
            word_frequencies[word] *= 5  # Hakaret kelimelerine 5 kat ağırlık ekleyin

    # WordCloud oluşturun
    wordcloud = WordCloud(stopwords=custom_stopwords, width=800, height=800, background_color='white').generate_from_frequencies(word_frequencies)

    # WordCloud görüntüsü
    plt.figure(figsize=(8, 8))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis("off")
    plt.title(title)
    plt.show()

# Wordcloud grafiğini oluştur
generate_wordcloud_with_weights(df['Processed_Text'], 'Zemberek WordCloud')

# Gerekli kütüphaneleri yükleyin
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from transformers import AutoTokenizer, AutoModel
import torch
from tqdm import tqdm
import numpy as np
import torch

# GPU kullanılabilir mi kontrol et
if torch.cuda.is_available():
    device = torch.device("cuda")
    print("GPU kullanılabilir. PyTorch modeli GPU'ya taşındı.")
else:
    device = torch.device("cpu")
    print("GPU kullanılmıyor. PyTorch modeli CPU'ya taşındı.")

# Google Drive'ı bağla (sadece Google Colab için)
drive.mount('/content/drive')

# Veri setini yükle
file_path = '/content/drive/My Drive/cleaned_data.csv'  # Dosyanızın tam yolunu belirtin
df = pd.read_csv(file_path)

# Etiketlerin Şifrelenmesi
label_encoder = LabelEncoder()
df['Offensive_Label'] = label_encoder.fit_transform(df['label'])

print("Şifrelenmiş Etiketler:")
print(df[['label', 'Offensive_Label']].drop_duplicates())

# BERTurk Tokenizer ve Modelini Yükleyin
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-turkish-cased")
model = AutoModel.from_pretrained("dbmdz/bert-base-turkish-cased")

# Metinleri Embedding'e çevirme fonksiyonu
def get_bert_embeddings(texts):
    embeddings = []
    for text in tqdm(texts, desc="Embedding İşlemi"):
        # Metnin string olup olmadığını ve boş olmadığını kontrol et
        if isinstance(text, str) and text:
            inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
            with torch.no_grad():
                outputs = model(**inputs)
            # [CLS] token çıkışları (Cümle Embedding'i)
            embeddings.append(outputs.last_hidden_state[:, 0, :].squeeze().numpy())
        else:
            # String olmayan veya boş metinleri işle (örneğin, boş bir embedding ile değiştir)
            embeddings.append(np.zeros(model.config.hidden_size))
    return embeddings

# Temizlenmiş metinleri Embedding'e dönüştürme
texts = df['Processed_Text'].tolist()
embeddings = get_bert_embeddings(texts)

# Embedding'leri DataFrame'e ekleme
embedding_df = pd.DataFrame(embeddings)
embedding_df.columns = [f"embedding_{i}" for i in range(embedding_df.shape[1])]
df = pd.concat([df, embedding_df], axis=1)

# Sonuçları kaydetme
output_file = "berturk_embeddings.csv"
df.to_csv(output_file, index=False)
print(f"Embedding sonuçları {output_file} dosyasına kaydedildi.")

from google.colab import drive
drive.mount('/content/drive')
output_file = "/content/drive/My Drive/berturk_embeddings.csv"
df.to_csv(output_file, index=False)
print(f"Embedding sonuçları {output_file} dosyasına kaydedildi.")

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from transformers import DistilBertTokenizer, DistilBertForSequenceClassification
from torch.nn.functional import softmax

from google.colab import drive

# Google Drive'ı bağlama
drive.mount('/content/drive')

# GPU kullanımı kontrolü
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Device: {device}")

# Dosya yolu
data_path = "/content/drive/My Drive/berturk_embeddings.csv"

# Veriyi yükleme
df = pd.read_csv(data_path)
print("Veri seti başarıyla yüklendi!")
print(df.head())

# Embedding ve Etiketlerin Hazırlanması
embedding_df = df[[col for col in df.columns if col.startswith("embedding_")]]
X = embedding_df.values
y = df['Offensive_Label'].values

# Eğitim, Validation ve Test Setine Bölme
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)  # %70 Eğitim, %30 Geçici
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # %15 Validation, %15 Test
val_dataset = EmbeddingDataset(X_val, y_val)
val_loader = DataLoader(val_dataset, batch_size=32)

# PyTorch Dataset Sınıfı
class EmbeddingDataset(Dataset):
    def __init__(self, embeddings, labels):
        self.embeddings = embeddings
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        return torch.tensor(self.embeddings[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)

train_dataset = EmbeddingDataset(X_train, y_train)
test_dataset = EmbeddingDataset(X_test, y_test)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32)

# Validation Dataset ve DataLoader
val_dataset = EmbeddingDataset(X_val, y_val)
val_loader = DataLoader(val_dataset, batch_size=32)


# Model Sınıfları
class LSTMClassifier(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(LSTMClassifier, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        x = x.unsqueeze(1)  # Batch boyutuna uygun hale getirme
        _, (hidden, _) = self.lstm(x)
        return self.fc(hidden[-1])

class BiLSTMClassifier(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(BiLSTMClassifier, self).__init__()
        self.bilstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(hidden_size * 2, num_classes)

    def forward(self, x):
        x = x.unsqueeze(1)
        _, (hidden, _) = self.bilstm(x)
        hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)
        return self.fc(hidden)

class GRUClassifier(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(GRUClassifier, self).__init__()
        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        x = x.unsqueeze(1)
        _, hidden = self.gru(x)
        return self.fc(hidden[-1])

class CNNClassifier(nn.Module):
    def __init__(self, input_size, num_classes):
        super(CNNClassifier, self).__init__()
        self.conv1 = nn.Conv1d(1, 64, kernel_size=3, padding=1)
        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)
        self.pool = nn.MaxPool1d(kernel_size=2)
        self.fc = nn.Linear((input_size // 2) * 128, num_classes)

    def forward(self, x):
        x = x.unsqueeze(1)  # Add channel dimension
        x = torch.relu(self.conv1(x))
        x = self.pool(x)
        x = torch.relu(self.conv2(x))
        x = x.view(x.size(0), -1)  # Flatten
        return self.fc(x)

# Eğitim Fonksiyonu
def train_model(model, train_loader, val_loader, criterion, optimizer, epochs):
    model.to(device)
    train_losses = []
    val_losses = []

    for epoch in range(epochs):
        model.train()
        train_loss = 0
        for embeddings, labels in train_loader:
            embeddings, labels = embeddings.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(embeddings)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        # Validation
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for embeddings, labels in val_loader:
                embeddings, labels = embeddings.to(device), labels.to(device)
                outputs = model(embeddings)
                loss = criterion(outputs, labels)
                val_loss += loss.item()

        train_losses.append(train_loss / len(train_loader))
        val_losses.append(val_loss / len(val_loader))

        print(f"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss/len(train_loader):.4f} - Validation Loss: {val_loss/len(val_loader):.4f}")

    # Eğitim ve Validation Kayıp Grafiği
    plt.figure(figsize=(10, 6))
    plt.plot(range(1, epochs + 1), train_losses, label='Train Loss')
    plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.show()



def evaluate_model(model, loader):
    model.eval()
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for embeddings, labels in loader:
            embeddings, labels = embeddings.to(device), labels.to(device)
            outputs = model(embeddings)
            preds = torch.argmax(outputs, dim=1).cpu().numpy()

            all_preds.extend(preds)
            all_labels.extend(labels.cpu().numpy())

    return all_labels, all_preds

def plot_confusion_matrix(labels, preds, num_classes, title):
    cm = confusion_matrix(labels, preds)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=list(range(num_classes)), yticklabels=list(range(num_classes)))
    plt.title(title)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

def print_classification_results(model_name, train_labels, train_preds, test_labels, test_preds):
    print(f"\n{model_name} Modeli - Eğitim Sonuçları:")
    print("Classification Report (Eğitim):")
    print(classification_report(train_labels, train_preds))

    print(f"\n{model_name} Modeli - Test Sonuçları:")
    print("Classification Report (Test):")
    print(classification_report(test_labels, test_preds))

    print(f"\n{model_name} Modeli Performans Değerleri:")
    train_accuracy = classification_report(train_labels, train_preds, output_dict=True)['accuracy']
    test_accuracy = classification_report(test_labels, test_preds, output_dict=True)['accuracy']
    print(f"Train Accuracy: {train_accuracy:.4f}")
    print(f"Test Accuracy: {test_accuracy:.4f}")

# Model Parametreleri
input_size = embedding_df.shape[1]  # Embedding boyutu
hidden_size = 128
num_classes = len(df['Offensive_Label'].unique())
learning_rate = 0.001
epochs = 10

# Modellerin Eğitimi ve Değerlendirilmesi
for ModelClass, model_name in zip([LSTMClassifier, BiLSTMClassifier, GRUClassifier, CNNClassifier], ["LSTM", "Bi-LSTM", "GRU", "CNN"]):
    print(f"\n{model_name} Modeli Eğitimde...")
    model = ModelClass(input_size, hidden_size, num_classes) if model_name != "CNN" else ModelClass(input_size, num_classes)
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    # Eğitim Süreci
    train_model(model, train_loader, val_loader, criterion, optimizer, epochs)

    # Değerlendirme
    train_labels, train_preds = evaluate_model(model, train_loader)
    test_labels, test_preds = evaluate_model(model, test_loader)

    # Sonuçları Yazdırma
    print_classification_results(model_name, train_labels, train_preds, test_labels, test_preds)

    # Confusion Matrix Görselleştirme
    plot_confusion_matrix(train_labels, train_preds, num_classes, f'{model_name} Modeli - Train Verisi Confusion Matrix')
    plot_confusion_matrix(test_labels, test_preds, num_classes, f'{model_name} Modeli - Test Verisi Confusion Matrix')


# DistilBERT Tokenizer ve Model
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
distilbert_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(df['Offensive_Label'].unique()))
distilbert_model.to(device)

# Metin ve Etiketlerin Hazırlanması
texts = df['text'].values
labels = df['Offensive_Label'].values

# Eğitim, Validation ve Test Setine Bölme
X_train, X_temp, y_train, y_temp = train_test_split(texts, labels, test_size=0.3, random_state=42)  # %70 Eğitim, %30 Geçici
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)    # %15 Validation, %15 Test


# Text ve Label Dataset için Listeye Çevir
train_texts = X_train.tolist()
test_texts = X_test.tolist()
val_texts = X_val.tolist()
val_dataset = DistilBERTDataset(val_texts, y_val, tokenizer)
val_loader = DataLoader(val_dataset, batch_size=16)

# DistilBERT Dataset ve DataLoader
class DistilBERTDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_len=128):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_len = max_len

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = self.texts[idx]
        label = self.labels[idx]
        encoding = self.tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=128,
            padding='max_length',
            truncation=True,
            return_tensors="pt",
            return_attention_mask=True
        )
        return {
            'input_ids': encoding['input_ids'].squeeze(0),
            'attention_mask': encoding['attention_mask'].squeeze(0),
            'label': torch.tensor(label, dtype=torch.long)
        }

train_dataset = DistilBERTDataset(train_texts, y_train, tokenizer)
test_dataset = DistilBERTDataset(test_texts, y_test, tokenizer)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=16)

# DistilBERT Eğitim Fonksiyonu
def train_distilbert(model, train_loader, val_loader, optimizer, epochs):
    train_losses = []  # Eğitim kayıplarını kaydetmek için liste
    val_losses = []    # Validation kayıplarını kaydetmek için liste

    for epoch in range(epochs):
        model.train()
        train_loss = 0
        for batch in train_loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['label'].to(device)

            optimizer.zero_grad()
            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        # Validation Kayıpları
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for batch in val_loader:
                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                labels = batch['label'].to(device)

                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
                val_loss += outputs.loss.item()

        # Kayıpları listelere ekleme
        train_losses.append(train_loss / len(train_loader))
        val_losses.append(val_loss / len(val_loader))

        print(f"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss/len(train_loader):.4f} - Validation Loss: {val_loss/len(val_loader):.4f}")

    # Eğitim ve Validation Kayıp Grafiği Çizimi
    plt.figure(figsize=(10, 6))
    plt.plot(range(1, epochs + 1), train_losses, label='Train Loss')
    plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.show()


# DistilBERT Değerlendirme Fonksiyonu
def evaluate_distilbert(model, loader):
    model.eval()
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for batch in loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['label'].to(device)

            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            preds = torch.argmax(softmax(outputs.logits, dim=1), dim=1).cpu().numpy()

            all_preds.extend(preds)
            all_labels.extend(labels.cpu().numpy())

    return all_labels, all_preds

# Model Parametreleri ve Eğitim
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(distilbert_model.parameters(), lr=2e-5)
epochs = 3

print("\nDistilBERT Modeli Eğitimde...")
train_distilbert(distilbert_model, train_loader, val_loader, optimizer, epochs)


# Performans Değerlendirmesi
train_labels, train_preds = evaluate_distilbert(distilbert_model, train_loader)
test_labels, test_preds = evaluate_distilbert(distilbert_model, test_loader)

print_classification_results("DistilBERT", train_labels, train_preds, test_labels, test_preds)
plot_confusion_matrix(train_labels, train_preds, len(df['Offensive_Label'].unique()), 'DistilBERT Modeli - Train Verisi Confusion Matrix')
plot_confusion_matrix(test_labels, test_preds, len(df['Offensive_Label'].unique()), 'DistilBERT Modeli - Test Verisi Confusion Matrix')

import torch
from transformers import DistilBertTokenizer, DistilBertForSequenceClassification

# Model ve Tokenizer'ı yükleme
model_name = "distilbert-base-uncased"  # Eğitilmiş model yolu veya önceden tanımlı model adı

tokenizer = DistilBertTokenizer.from_pretrained(model_name)
model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # İki sınıflı tahmin

# Modeli değerlendirme moduna al ve GPU kullanımı kontrolü
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

# Hakaret kelimeleri listesi
hate_words = ["şerefsiz", "aptal", "salak", "kötü", "çirkin", "nefret", "gerizekalı", "haksız", "manyak", "amk", "aq", "iğrenç"]

def contains_hate_words(text):
    """
    Metin içerisinde hakaret kelimelerinin olup olmadığını kontrol eder.

    Args:
        text (str): Kontrol edilecek metin.

    Returns:
        bool: Hakaret kelimesi içeriyorsa True, aksi halde False.
    """
    for word in hate_words:
        if word in text.lower():
            return True
    return False

def predict_offensive(text):
    """
    Verilen metnin offensive mi yoksa not-offensive mi olduğunu tahmin eder.

    Args:
        text (str): Tahmin edilecek metin.

    Returns:
        str: Tahmin edilen sınıf etiketi ("offensive" veya "not-offensive").
        float: Saldırganlık olasılığı.
    """
    # Hakaret kelimelerini kontrol et
    if contains_hate_words(text):
        return "offensive", 1.0

    # Metni tokenize et
    inputs = tokenizer.encode_plus(
        text,
        add_special_tokens=True,
        max_length=128,
        padding="max_length",
        truncation=True,
        return_tensors="pt"
    )

    # Girdileri GPU'ya taşı (mevcutsa)
    input_ids = inputs["input_ids"].to(device)
    attention_mask = inputs["attention_mask"].to(device)

    # Model tahmini
    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        probabilities = torch.softmax(logits, dim=1).squeeze()
        predicted_class = torch.argmax(probabilities).item()

    # Sınıf etiketleri
    label_map = {0: "not-offensive", 1: "offensive"}
    predicted_label = label_map[predicted_class]

    return predicted_label, probabilities[predicted_class].item()

# Örnek Kullanım
if __name__ == "__main__":
    example_text = "şerefsiz herifin tekisin senden iğreniyorum"
    label, probability = predict_offensive(example_text)
    print(f"Metin: {example_text}")
    print(f"Tahmin: {label}")
    print(f"Olasılık: {probability:.4f}")

# Örnek Kullanım
if __name__ == "__main__":
    example_text = "seni seviyorum iyi ki varsın"
    label, probability = predict_offensive(example_text)
    print(f"Metin: {example_text}")
    print(f"Tahmin: {label}")
    print(f"Olasılık: {probability:.4f}")

# Örnek Kullanım
if __name__ == "__main__":
    example_text = "ıyy bu nasıl bir elbise hiç beğenmedim"
    label, probability = predict_offensive(example_text)
    print(f"Metin: {example_text}")
    print(f"Tahmin: {label}")
    print(f"Olasılık: {probability:.4f}")

# Örnek Kullanım
if __name__ == "__main__":
    example_text = "gıcık oluyorum sana ya "
    label, probability = predict_offensive(example_text)
    print(f"Metin: {example_text}")
    print(f"Tahmin: {label}")
    print(f"Olasılık: {probability:.4f}")

# Örnek Kullanım
if __name__ == "__main__":
    example_text = "Allah devletimize zeval vermesin"
    label, probability = predict_offensive(example_text)
    print(f"Metin: {example_text}")
    print(f"Tahmin: {label}")
    print(f"Olasılık: {probability:.4f}")